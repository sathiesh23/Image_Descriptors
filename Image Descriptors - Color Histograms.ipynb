{"cells":[{"cell_type":"markdown","metadata":{"id":"gTscThyuePHG"},"source":["### **IMAGE DESCRIPTOR - COLOR HISTOGRAMS**\n","* Unlike the **mean and standard deviation which attempt to summarize the pixel intensity distribution**, a **color histogram explicitly represents it**.\n","* In fact, a **color histogram is the color distribution**.\n","* Assumption that **images with similar color distributions contain equally similar visual contents**.\n","* In this **example**, we are going to take small dataset of images — but instead of ranking, we are going to cluster and group them into two distinct classes using color histograms."]},{"cell_type":"markdown","metadata":{"id":"rF9DhNYiePHK"},"source":["### **COLOR HISTOGRAMS:**\n","* **Color histogram counts the number of times a given pixel intensity occurs in an image**.\n","* Using a color histogram we can express the **actual distribution or “amount” of each color in an image**.\n","* The **counts for each color/color range are used as feature vectors**.\n","* If we decided to utilize a **3D color histogram with 8 bins per channel**, we could represent any image of any size using only **8 x 8 x 8 = 512 bins, or a feature vector of 512-d**.\n","* The **size of an image has no effect on our output color histogram** — although it’s wise to resize large images to more manageable dimension to increase the speed of the histogram computation."]},{"cell_type":"markdown","metadata":{"id":"-vMTpF64ePHK"},"source":["### **k-means Clustering Algorithm:**\n","* k-means is a **clustering algorithm**.\n","* k-means is to **partition n data points into k clusters**.\n","* **Each of the n data points will be assigned to a cluster with the nearest mean**.\n","* The **mean of each cluster** is called its “**centroid**” or “**center**”.\n","* **Applying k-means yields k separate clusters of the original n data points**.\n","* Data points inside a particular cluster are considered to be “more similar” to each other than data points that belong to other clusters.\n","* In this particular **program**, we will be **clustering the color histograms extracted from the images in our dataset** — but in reality, you could be clustering any type of feature vector.\n","* **Histograms that belong to a given cluster will be more similar in color distribution** than histograms belonging to a separate cluster.\n","* One **caveat of k-means** is that we **need to specify the number of clusters** we want to generate ahead of time.\n","* There are **algorithms that automatically select the optimal value of k**.\n","* For the time being, we will be manually supplying a value of k=2 to separate the two classes of images."]},{"cell_type":"markdown","metadata":{"id":"-Hw7D9NWePHL"},"source":["**Program** : Cluster the vacation photo dataset into two distinct groups. At first, need to extract color histograms from each of the 10 images in the dataset. We will create a LabHistogram class to extract color histograms from images in the L*a*b* color space.\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":556,"status":"ok","timestamp":1713059032185,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"},"user_tz":-330},"id":"nzq55c0ZePHL"},"outputs":[],"source":["# import the necessary packages\n","from sklearn.cluster import KMeans\n","from imutils import paths\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import cv2\n","from matplotlib import pyplot as plt"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":339,"status":"ok","timestamp":1713059034750,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"},"user_tz":-330},"id":"PihCoEh2ePHM"},"outputs":[],"source":["def describe(image, mask=None):\n","\t# convert the image to the L*a*b* color space, compute a 3D histogram and normalize it\n","\t# Euclidean distance between two colors in the L*a*b* has perceptual and noticeable meaning.\n","\t# And since the k-means clustering algorithm assumes a Euclidean space, we will get better\n","  # clusters by using the L*a*b* color space than RGB or HSV.\n","\t# If we do not normalize, then images with the exact same contents but different sizes would\n","  # have dramatically different histograms. Instead, by normalizing our histogram we ensure that\n","  # the width and height of our input image has no effect on the output histogram.\n","\tlab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n","\thist = cv2.calcHist([lab], [0, 1, 2], mask, [8,8,8],[0, 256, 0, 256, 0, 256])\n","\thist = cv2.normalize(hist, hist).flatten()\n","\t# return the histogram\n","\treturn hist"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":324,"status":"ok","timestamp":1713059038622,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"},"user_tz":-330},"id":"IKSL4t8hePHN","outputId":"212e55ec-ae3e-4d8e-a2a8-6f757079ae67"},"outputs":[{"output_type":"stream","name":"stdout","text":["['/content/sample_data/dataset/antelopecanyon_01.png'\n"," '/content/sample_data/dataset/antelopecanyon_02.png'\n"," '/content/sample_data/dataset/antelopecanyon_03.png'\n"," '/content/sample_data/dataset/antelopecanyon_04.png'\n"," '/content/sample_data/dataset/antelopecanyon_05.png'\n"," '/content/sample_data/dataset/grandcanyon_01.png'\n"," '/content/sample_data/dataset/grandcanyon_02.png'\n"," '/content/sample_data/dataset/grandcanyon_03.png'\n"," '/content/sample_data/dataset/grandcanyon_04.png'\n"," '/content/sample_data/dataset/grandcanyon_05.png']\n"]}],"source":["#  initialize a list, data, to store the color histograms extracted from our image.\n","data = []\n","\n","# grab the image paths from the dataset directory (upload the dataset to the specified location)\n","imagePaths = list(paths.list_images(\"/content/sample_data/dataset\"))\n","imagePaths = np.array(sorted(imagePaths))\n","print(imagePaths)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":321,"status":"ok","timestamp":1713059040736,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"},"user_tz":-330},"id":"Jgq4s12qePHO"},"outputs":[],"source":["# loop over the input dataset of images\n","for imagePath in imagePaths:\n","\t# load the image, describe the image, then update the list of data\n","\timage = cv2.imread(imagePath)\n","\thist = describe(image)\n","\tdata.append(hist)\n","\n","#print (data)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":336,"status":"ok","timestamp":1713059424134,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"},"user_tz":-330},"id":"9QUCE1SmePHO"},"outputs":[],"source":["# Now that we have all of our color features extracted, we can cluster the feature vector using\n","# the k-means algorithm. We initialize k-means using the supplied number of clusters via\n","# command line argument. And a call to clt.fit_predict  not only performs the actual clustering,\n","# but performs the prediction as to which histogram (and thus which associated image) belongs\n","# to which of the 2 clusters.\n","# Number of times the k-means algorithm is run with different centroid seeds.\n","# The final results is the best output of n_init consecutive runs in terms of inertia.\n","clt = KMeans(n_clusters=2, n_init=10)\n","labels = clt.fit_predict(data)"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1JiE_IeDco-oFZ8FDzFPEENJ2CyTgNzrN"},"id":"tDafqAwCePHO","outputId":"83434db9-ea7c-4ef8-e9b6-aca7b188fbaf","executionInfo":{"status":"ok","timestamp":1713059431415,"user_tz":-330,"elapsed":3810,"user":{"displayName":"Sathiesh Kumar V","userId":"09206616064616230567"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# print labels\n","# Now that we have our color histograms clustered, we need to grab the unique IDs for each\n","# cluster. This is handled by making a call to np.unique, which returns the unique values inside\n","# a list. For each unique label , we need to grab the image paths that belong to the cluster. And\n","# for each of the images that belong to the current cluster, we load and display the image to our\n","# screen. loop over the unique labels.\n","for label in np.unique(labels):\n","\t# grab all image paths that are assigned to the current label\n","\tlabelPaths = imagePaths[np.where(labels == label)]\n","\t# loop over the image paths that belong to the current label\n","\tfor (i, path) in enumerate(labelPaths):\n","\t\t# load the image and display it\n","\t\timage = cv2.imread(path)\n","\t\tprint(label + 1)\n","\t\tprint(i + 1)\n","\t\tcv2_imshow(image)\n","\n","\t# wait for a keypress and then close all open windows\n","\tcv2.waitKey(0)\n","\tcv2.destroyAllWindows()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qJ49sU4OePHP"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.6"}},"nbformat":4,"nbformat_minor":0}